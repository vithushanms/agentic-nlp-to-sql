{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is just a sample semantic context used for this example. You must update your context here\n",
    "semantic_context = \"\"\"\n",
    "This is a online store where, the shop sell PC hardware. The customers are from various locations and the orders are being tracked in the source database attached here\n",
    "\"\"\"\n",
    "\n",
    "agent_prompt = f\"\"\"\n",
    "You are a helpful assistant that can generate a SQL query based on the user's question and semantic context.\n",
    "You can also execute a MySQL query and return the result.\n",
    "\n",
    "here is the semantic context you can use to understand the business and generate the query:\n",
    "{semantic_context}\n",
    "\n",
    "Take the following steps to provide the answer:\n",
    "1. write reasoning steps to approach the question.\n",
    "2. generate the sql query based on the reasoning steps.\n",
    "3. if you want to profile any column before you executing the query to add the correct filter, for example if there is a status column, you can run DISTICT query on that column to get the unique values and then use that to add the correct filter.\n",
    "4. execute the sql query and return the result (please add max limit of records as 100 to the query before executing it, otherwise it may go out of LLM context window).\n",
    "5. if the result is not what you expected, please write the new reasoning steps and generate the new sql query and execute it again.\n",
    "\n",
    "Expectation:\n",
    "- try to give the data in a table format.\n",
    "- don't hallucinat, just give the answer always based on the information available in the source.\n",
    "- if the information is not present in the db or the result is empty, please inform that to the user rather than hallucinating.\n",
    "- if you don't have enough information to generate the query, ask for more information from the user.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_index import ModelVectorIndex\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def get_db_context(reasoning_steps: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate SQL query based on natural language question using semantic context and table relationships.\n",
    "    \n",
    "    Args:\n",
    "        reasoning_steps: The user's natural language reasoning_steps about the data\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated SQL query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize vector index\n",
    "        vector_index = ModelVectorIndex()\n",
    "        index = vector_index.load_index(\"fs_cache/vector_index\")\n",
    "        \n",
    "        # Load relationships\n",
    "        relationships_path = Path(\"fs_cache/relationships\")\n",
    "        relationships = []\n",
    "        for file_path in relationships_path.glob(\"*.json\"):\n",
    "            with open(file_path, \"r\") as f:\n",
    "                relationships.append(json.load(f))\n",
    "        \n",
    "        docs_and_scores = index.similarity_search_with_score(reasoning_steps, k=5)\n",
    "        similarity_threshold = 1.6\n",
    "\n",
    "        relevant_docs = [doc for doc, score in docs_and_scores if score <= similarity_threshold]\n",
    "\n",
    "        models = [json.loads(doc.page_content) for doc in relevant_docs]\n",
    "\n",
    "        grouped = []\n",
    "        for model in models:\n",
    "            model_name = model[\"name\"]\n",
    "            related_rels = [\n",
    "                rel for rel in relationships\n",
    "                if model_name in rel.get(\"models\", [])\n",
    "            ]\n",
    "            grouped.append({\n",
    "                \"model\": model,\n",
    "                \"relationships\": related_rels\n",
    "            })\n",
    "\n",
    "        return grouped\n",
    "  \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DDL for models and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ddl_for_models_and_relationships(model_relationships):\n",
    "    # Build a lookup for model name -> (db, columns)\n",
    "    model_lookup = {}\n",
    "    for entry in model_relationships:\n",
    "        model = entry[\"model\"]\n",
    "        model_lookup[model[\"name\"]] = {\n",
    "            \"db\": model[\"database\"],\n",
    "            \"columns\": {col[\"name\"]: col for col in model[\"columns\"]},\n",
    "        }\n",
    "\n",
    "    ddls = []\n",
    "    for entry in model_relationships:\n",
    "        model = entry[\"model\"]\n",
    "        table_name = model[\"name\"]\n",
    "        db_name = model[\"database\"]\n",
    "        columns = model[\"columns\"]\n",
    "        table_desc = model.get(\"properties\", {}).get(\"description\", \"\")\n",
    "        pk_candidates = [\n",
    "            col[\"name\"]\n",
    "            for col in columns\n",
    "            if col[\"name\"].lower().endswith(\"id\") and col.get(\"notNull\", 0)\n",
    "        ]\n",
    "        # Compose DDL\n",
    "        ddl_lines = []\n",
    "        ddl_lines.append(f\"-- Table: {db_name}.{table_name}\")\n",
    "        if table_desc:\n",
    "            ddl_lines.append(f\"-- Description: {table_desc}\")\n",
    "        ddl_lines.append(f\"CREATE TABLE {db_name}.{table_name} (\")\n",
    "        col_lines = []\n",
    "        for col in columns:\n",
    "            col_name = col[\"name\"]\n",
    "            col_type = col[\"type\"]\n",
    "            not_null = \"NOT NULL\" if col.get(\"notNull\", 0) else \"\"\n",
    "            desc = col.get(\"properties\", {}).get(\"description\", \"\")\n",
    "            comment = f\" -- {desc}\" if desc else \"\"\n",
    "            col_lines.append(f\"    {col_name} {col_type} {not_null}{comment}\".rstrip())\n",
    "        # Add primary key if any\n",
    "        if pk_candidates:\n",
    "            pk = pk_candidates[0]\n",
    "            col_lines.append(f\"    ,PRIMARY KEY ({pk})\")\n",
    "        ddl_lines.append(\",\\n\".join(col_lines))\n",
    "        ddl_lines.append(\");\")\n",
    "        ddls.append(\"\\n\".join(ddl_lines))\n",
    "\n",
    "    # Now generate foreign key constraints\n",
    "    fk_lines = []\n",
    "    for entry in model_relationships:\n",
    "        relationships = entry.get(\"relationships\", [])\n",
    "        for rel in relationships:\n",
    "            # Parse the join condition: \"table1.col1 = table2.col2\"\n",
    "            cond = rel.get(\"condition\", \"\")\n",
    "            if \"=\" not in cond:\n",
    "                continue\n",
    "            left, right = [x.strip() for x in cond.split(\"=\")]\n",
    "            left_table, left_col = left.split(\".\")\n",
    "            right_table, right_col = right.split(\".\")\n",
    "            # Only add FK if both tables are in the model_lookup\n",
    "            if left_table in model_lookup and right_table in model_lookup:\n",
    "                # Try to add FK from left_table to right_table\n",
    "                fk_lines.append(\n",
    "                    f\"ALTER TABLE {model_lookup[left_table]['db']}.{left_table}\\n\"\n",
    "                    f\"    ADD FOREIGN KEY ({left_col}) REFERENCES {model_lookup[right_table]['db']}.{right_table}({right_col});\"\n",
    "                )\n",
    "                # For MANY_TO_MANY, you might want to add both directions, but usually only one is needed\n",
    "\n",
    "    return \"\\n\\n\".join(ddls + fk_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SQL query from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def generate_sql_query_from_context_and_ddl(ddl: str, question: str, semantic_context: str, resoning_steps: str, feedback:str = None) -> list:\n",
    "    \"\"\"\n",
    "    This function generates a SQL query based on the provided DDL, question, and semantic context.\n",
    "\n",
    "    Args:\n",
    "        ddl: The DDL of the models\n",
    "        question: The user's question\n",
    "        semantic_context: The business context and semantic information about the domain\n",
    "        resoning_steps: The reasoning steps for the query\n",
    "        feedback: provide the error message or any feedback to improve the query, if this tool is called again.\n",
    "\n",
    "    Returns:\n",
    "        sql_query: The generated SQL query\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "        Generate a SQL query based on the following DDLs, question, and semantic context:\n",
    "\n",
    "        DDLs:\n",
    "        ----*****DDLs*****----\n",
    "        {ddl}\n",
    "        ----*****END OF DDLs*****----\n",
    "\n",
    "        Question:\n",
    "        ----*****Question*****----\n",
    "        {question}\n",
    "        ----*****END OF Question*****----\n",
    "\n",
    "            Resoning Steps to approach the question:\n",
    "        ----*****Resoning Steps*****----\n",
    "        {resoning_steps}\n",
    "        ----*****END OF Resoning Steps*****----\n",
    "\n",
    "        Semantic Context:\n",
    "        ----*****Semantic Context*****----\n",
    "        {semantic_context}\n",
    "        ----*****END OF Semantic Context*****----\n",
    "\n",
    "        Note: please include the database name in the query. and only use the table names and column names that are present in the DDLs and relationship. please don't halucinate or add any new table names or column names. if you don't have enough information to generate the query, please return \"No information found\"\n",
    "\n",
    "        Expectation:\n",
    "            - Please only returns the SQL query, nothing else.\n",
    "            - you may generate one or more queries to answer the question.\n",
    "            - please try to use joins whenever possble\n",
    "            - always write the query in mysql syntax.\n",
    "        \"\"\"\n",
    "\n",
    "        if feedback:\n",
    "            prompt += f\"\\n\\nFeedback previous attempt: {feedback}\"\n",
    "\n",
    "        model = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "        response = model.invoke(prompt)\n",
    "\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_sql_query(user_question: str, semantic_context: str, reasoning_steps: str, feedback:str = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate a SQL query based on the user's question and semantic context.\n",
    "\n",
    "    Args:\n",
    "        user_question: The user's question\n",
    "        semantic_context: The business context and semantic information about the domain\n",
    "        reasoning_steps: The reasoning steps for the query\n",
    "        feedback: provide the error message or any feedback along with the previous attempt query to improve the query, if this tool is called again.\n",
    "    Returns:\n",
    "        sql_query: The generated SQL query\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        context = get_db_context(reasoning_steps)\n",
    "        ddl = generate_ddl_for_models_and_relationships(context)\n",
    "        sql_query = generate_sql_query_from_context_and_ddl(ddl, user_question, semantic_context, reasoning_steps, feedback)\n",
    "        return sql_query\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute_mysql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "@tool\n",
    "def execute_mysql_query(query: str, database_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    This function will execute the mysql query and return the result.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The MySQL query to execute\n",
    "        database_name (str): The specific database to connect to\n",
    "    \n",
    "    Returns:\n",
    "        list: The query results\n",
    "    \"\"\"\n",
    "    # base_url = os.getenv(\"MYSQL_URL\")\n",
    "\n",
    "    username = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASS\")\n",
    "    host = os.getenv(\"DB_HOST\")\n",
    "    port = os.getenv(\"DB_PORT\")\n",
    "    url = f\"mysql+mysqlconnector://{username}:{password}@{host}/{database_name}\"\n",
    "\n",
    "    \n",
    "    engine = create_engine(url)\n",
    "    try:\n",
    "        print(f\"Executing query: {query} in database: {database_name}\")\n",
    "        with engine.connect() as connection:\n",
    "            # Convert the string query to a SQLAlchemy text object\n",
    "            sql_query = text(query)\n",
    "            result = connection.execute(sql_query)\n",
    "            return result.fetchall()\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the sql agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0.0)\n",
    "\n",
    "sql_agent = create_react_agent(\n",
    "    name=\"sql_agent\",\n",
    "    model=model,\n",
    "    tools=[generate_sql_query, execute_mysql_query],\n",
    "    prompt=agent_prompt.format(semantic_context=semantic_context),\n",
    "    checkpointer=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the sql agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your desired question goes here\n",
    "messages = [HumanMessage(content=\"\"\"\n",
    "Who is my best customer? and why?\n",
    "\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Reasoning Steps:\\n1. \"Best customer\" typically refers to the customer who has contributed the most value to the business, usually by total order value.\\n2. To determine this, I need to sum the total order value for each customer and identify the customer with the highest total.\\n3. I will join the customer and order tables, group by customer, sum the order values, and order the result in descending order to get the top customer.\\n4. I will also include the reason: the best customer is the one with the highest total order value.\\n\\nLet\\'s generate and execute the query.', additional_kwargs={'tool_calls': [{'id': 'call_lfut6T9lwrGjkKbWC8xXptB9', 'function': {'arguments': '{\"user_question\":\"Who is my best customer? and why?\",\"semantic_context\":\"This is a online store where, the shop sell PC hardware. The customers are from various locations and the orders are being tracked in the source database attached here\",\"reasoning_steps\":\"1. Sum the total order value for each customer. 2. Identify the customer with the highest total order value. 3. Join the customer and order tables, group by customer, sum the order values, and order the result in descending order. 4. Limit the result to the top customer. 5. The best customer is the one with the highest total order value.\"}', 'name': 'generate_sql_query'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 262, 'prompt_tokens': 1012, 'total_tokens': 1274, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_2d9626f3cf', 'id': 'chatcmpl-BYZ8o4B8q4gOy2vLMR7hNRJBfgS5k', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='sql_agent', id='run--3ed1158c-1369-440d-b8af-f0d001fe4966-0', tool_calls=[{'name': 'generate_sql_query', 'args': {'user_question': 'Who is my best customer? and why?', 'semantic_context': 'This is a online store where, the shop sell PC hardware. The customers are from various locations and the orders are being tracked in the source database attached here', 'reasoning_steps': '1. Sum the total order value for each customer. 2. Identify the customer with the highest total order value. 3. Join the customer and order tables, group by customer, sum the order values, and order the result in descending order. 4. Limit the result to the top customer. 5. The best customer is the one with the highest total order value.'}, 'id': 'call_lfut6T9lwrGjkKbWC8xXptB9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1012, 'output_tokens': 262, 'total_tokens': 1274, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [ToolMessage(content='```sql\\nSELECT c.CustomerId, c.CustomerName, SUM(co.TotalAmount) AS TotalOrderValue\\nFROM customer_db.customer_order co\\nJOIN customer_db.customer c ON co.CustomerId = c.CustomerId\\nGROUP BY c.CustomerId, c.CustomerName\\nORDER BY TotalOrderValue DESC\\nLIMIT 1;\\n```', name='generate_sql_query', id='ed7f575a-ba36-49d3-89a2-9c49e4ce59f2', tool_call_id='call_lfut6T9lwrGjkKbWC8xXptB9')]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ERWUrQsK4thi0HMXuH7nZiBW', 'function': {'arguments': '{\"query\":\"SELECT c.CustomerId, c.CustomerName, SUM(co.TotalAmount) AS TotalOrderValue\\\\nFROM customer_db.customer_order co\\\\nJOIN customer_db.customer c ON co.CustomerId = c.CustomerId\\\\nGROUP BY c.CustomerId, c.CustomerName\\\\nORDER BY TotalOrderValue DESC\\\\nLIMIT 1;\",\"database_name\":\"customer_db\"}', 'name': 'execute_mysql_query'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 1357, 'total_tokens': 1438, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_2d9626f3cf', 'id': 'chatcmpl-BYZ8uEHyP7Iy1teyusBkbeoCtXmoK', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='sql_agent', id='run--02ec73c9-a09e-4faa-86a5-3f0d8e8da1d9-0', tool_calls=[{'name': 'execute_mysql_query', 'args': {'query': 'SELECT c.CustomerId, c.CustomerName, SUM(co.TotalAmount) AS TotalOrderValue\\nFROM customer_db.customer_order co\\nJOIN customer_db.customer c ON co.CustomerId = c.CustomerId\\nGROUP BY c.CustomerId, c.CustomerName\\nORDER BY TotalOrderValue DESC\\nLIMIT 1;', 'database_name': 'customer_db'}, 'id': 'call_ERWUrQsK4thi0HMXuH7nZiBW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1357, 'output_tokens': 81, 'total_tokens': 1438, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "Executing query: SELECT c.CustomerId, c.CustomerName, SUM(co.TotalAmount) AS TotalOrderValue\n",
      "FROM customer_db.customer_order co\n",
      "JOIN customer_db.customer c ON co.CustomerId = c.CustomerId\n",
      "GROUP BY c.CustomerId, c.CustomerName\n",
      "ORDER BY TotalOrderValue DESC\n",
      "LIMIT 1; in database: customer_db\n",
      "{'messages': [ToolMessage(content=\"[(2, 'Emma Johnson', Decimal('4634.33'))]\", name='execute_mysql_query', id='ed45eda5-ae4d-47ef-b170-47910e0c600b', tool_call_id='call_ERWUrQsK4thi0HMXuH7nZiBW')]}\n",
      "{'messages': [AIMessage(content='Your best customer is Emma Johnson (CustomerId: 2).\\n\\nReason: Emma Johnson has the highest total order value, having spent a total of 4634.33 in your store. This makes her your most valuable customer based on total purchases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 1465, 'total_tokens': 1516, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_2d9626f3cf', 'id': 'chatcmpl-BYZ8vIBCdPy13H4eHaQJUbSVxh7m3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='sql_agent', id='run--66a6a7a5-52b2-436e-a3dc-4aafaa3a128f-0', usage_metadata={'input_tokens': 1465, 'output_tokens': 51, 'total_tokens': 1516, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"123\"}, \"recursion_limit\": 20}\n",
    "final_message = \"\"\n",
    "for event in sql_agent.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "        if v['messages'] and isinstance(v['messages'], list):\n",
    "            final_message = v['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your best customer is Emma Johnson (CustomerId: 2).\n",
       "\n",
       "Reason: Emma Johnson has the highest total order value, having spent a total of 4634.33 in your store. This makes her your most valuable customer based on total purchases."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "\n",
    "def display_markdown_with_tables(markdown_text):\n",
    "    \"\"\"\n",
    "    Display markdown text with tables in a Jupyter notebook.\n",
    "    Tables are rendered as pandas DataFrames for better visuals.\n",
    "    \"\"\"\n",
    "    lines = markdown_text.split('\\n')\n",
    "    table_block = []\n",
    "    in_table = False\n",
    "    text_block = []\n",
    "\n",
    "    def show_text_block():\n",
    "        if text_block:\n",
    "            display(Markdown('\\n'.join(text_block)))\n",
    "            text_block.clear()\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # Detect start of a markdown table\n",
    "        if re.match(r'^\\s*\\|.*\\|\\s*$', line):\n",
    "            # If we were collecting text, display it\n",
    "            show_text_block()\n",
    "            # Start collecting table lines\n",
    "            table_block = [line]\n",
    "            i += 1\n",
    "            # Collect all contiguous table lines\n",
    "            while i < len(lines) and re.match(r'^\\s*\\|.*\\|\\s*$', lines[i]):\n",
    "                table_block.append(lines[i])\n",
    "                i += 1\n",
    "            # Try to parse and display the table\n",
    "            try:\n",
    "                # Remove leading/trailing whitespace\n",
    "                table_str = '\\n'.join([l.strip() for l in table_block])\n",
    "                # Pandas expects no leading/trailing pipes, so remove them\n",
    "                table_str = re.sub(r'^\\|', '', table_str, flags=re.MULTILINE)\n",
    "                table_str = re.sub(r'\\|$', '', table_str, flags=re.MULTILINE)\n",
    "                df = pd.read_csv(io.StringIO(table_str), sep='|')\n",
    "                display(df)\n",
    "            except Exception as e:\n",
    "                # If parsing fails, just display as markdown\n",
    "                display(Markdown('\\n'.join(table_block)))\n",
    "        else:\n",
    "            text_block.append(line)\n",
    "            i += 1\n",
    "    # Show any remaining text\n",
    "    show_text_block()\n",
    "\n",
    "\n",
    "display_markdown_with_tables(final_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-nlp-to-sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
